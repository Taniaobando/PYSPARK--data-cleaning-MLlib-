{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conocimiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------LIMPIEZA DE LOS DATOS------------------------------#\n",
    "#Importando librerias\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql import SparkSession, DataFrameStatFunctions, DataFrameNaFunctions\n",
    "from pyspark.sql.functions import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------#\n",
    "#Calcula la correlación de todas las variables de un dataframe\n",
    "#Entradas  dataframe: Dataframe de Spark\n",
    "#          headings: encabezado del dataframe (nombre de cada columna)\n",
    "#Salidas   corr: Lista de listas con la correlación de todas las variables \n",
    "def correlation(dataframe,headings):\n",
    "    n = len(headings)\n",
    "    corr = [[1 for _ in range(n)] for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            corr[i][j] = dataframe.corr(headings[i],headings[j])\n",
    "            corr[j][i] = corr[i][j]\n",
    "    return corr\n",
    "#----------------------------------------------------------------------------#\n",
    "\n",
    "#Encabezado del dataframe\n",
    "headings = ['school','sex','age','address','famsize','Pstatus','Medu','Fedu','Mjob',\n",
    " 'Fjob','reason','guardian','traveltime','studytime','failures','schoolsup',\n",
    " 'famsup','paid','activities','nursery','higher','internet','romantic',\n",
    " 'famrel','freetime','goout','Dalc','Walc','health','absences','G1','G2','G3']\n",
    "spark = SparkSession.builder.appName(\"Student\").getOrCreate()\n",
    "\n",
    "#Crear dataframe\n",
    "df=spark.read.csv('student-por.csv',sep=';',header=True)\n",
    "#df.show()\n",
    "\n",
    "#Tamaño del dataset\n",
    "#print(df.count())\n",
    "#El dataframe tiene 649 registros\n",
    "\n",
    "#Tipos de dato de cada variable\n",
    "#print(df.dtypes)\n",
    "#Todos los datos del dataframe inicial son de tipo string\n",
    "\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Null data\\ntotal_null = df.filter(\"school is null\").count() + df.filter(\"sex is null\").count() + df.filter(\"age is null\").count()\\ntotal_null+= df.filter(\"address is null\").count() + df.filter(\"famsize is null\").count() + df.filter(\"Pstatus is null\").count()\\ntotal_null+= df.filter(\"Medu is null\").count() + df.filter(\"Fedu is null\").count() + df.filter(\"Mjob is null\").count()\\ntotal_null+= df.filter(\"Fjob is null\").count() + df.filter(\"reason is null\").count() + df.filter(\"guardian is null\").count()\\ntotal_null+= df.filter(\"traveltime is null\").count() + df.filter(\"studytime is null\").count() + df.filter(\"failures is null\").count()\\ntotal_null+= df.filter(\"schoolsup is null\").count() + df.filter(\"famsup is null\").count() + df.filter(\"paid is null\").count()\\ntotal_null+= df.filter(\"activities is null\").count() + df.filter(\"nursery is null\").count() + df.filter(\"higher is null\").count()\\ntotal_null+= df.filter(\"internet is null\").count() + df.filter(\"romantic is null\").count() + df.filter(\"famrel is null\").count()\\ntotal_null+= df.filter(\"freetime is null\").count() + df.filter(\"goout is null\").count() + df.filter(\"Dalc is null\").count()\\ntotal_null+= df.filter(\"Walc is null\").count() + df.filter(\"health is null\").count() + df.filter(\"absences is null\").count()\\ntotal_null+= df.filter(\"G1 is null\").count() + df.filter(\"G2 is null\").count() + df.filter(\"G3 is null\").count()\\nprint(total_null)\\n#Encontramos que el dataframe inicial no tiene datos faltantes\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Null data\n",
    "total_null = df.filter(\"school is null\").count() + df.filter(\"sex is null\").count() + df.filter(\"age is null\").count()\n",
    "total_null+= df.filter(\"address is null\").count() + df.filter(\"famsize is null\").count() + df.filter(\"Pstatus is null\").count()\n",
    "total_null+= df.filter(\"Medu is null\").count() + df.filter(\"Fedu is null\").count() + df.filter(\"Mjob is null\").count()\n",
    "total_null+= df.filter(\"Fjob is null\").count() + df.filter(\"reason is null\").count() + df.filter(\"guardian is null\").count()\n",
    "total_null+= df.filter(\"traveltime is null\").count() + df.filter(\"studytime is null\").count() + df.filter(\"failures is null\").count()\n",
    "total_null+= df.filter(\"schoolsup is null\").count() + df.filter(\"famsup is null\").count() + df.filter(\"paid is null\").count()\n",
    "total_null+= df.filter(\"activities is null\").count() + df.filter(\"nursery is null\").count() + df.filter(\"higher is null\").count()\n",
    "total_null+= df.filter(\"internet is null\").count() + df.filter(\"romantic is null\").count() + df.filter(\"famrel is null\").count()\n",
    "total_null+= df.filter(\"freetime is null\").count() + df.filter(\"goout is null\").count() + df.filter(\"Dalc is null\").count()\n",
    "total_null+= df.filter(\"Walc is null\").count() + df.filter(\"health is null\").count() + df.filter(\"absences is null\").count()\n",
    "total_null+= df.filter(\"G1 is null\").count() + df.filter(\"G2 is null\").count() + df.filter(\"G3 is null\").count()\n",
    "print(total_null)\n",
    "#Encontramos que el dataframe inicial no tiene datos faltantes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Casteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------#\n",
    "#Reemplazar valores categoricos a númericos\n",
    "df = df.withColumn(\"school\", regexp_replace(\"school\", \"GP\", \"0\"))\n",
    "df = df.withColumn(\"school\", regexp_replace(\"school\", \"MS\", \"1\"))\n",
    "df = df.withColumn(\"sex\", regexp_replace(\"sex\", \"F\", \"0\"))\n",
    "df = df.withColumn(\"sex\", regexp_replace(\"sex\", \"M\", \"1\"))\n",
    "df = df.withColumn(\"address\", regexp_replace(\"address\", \"R\", \"0\"))\n",
    "df = df.withColumn(\"address\", regexp_replace(\"address\", \"U\", \"1\"))\n",
    "df = df.withColumn(\"famsize\", regexp_replace(\"famsize\", \"LE3\", \"0\"))\n",
    "df = df.withColumn(\"famsize\", regexp_replace(\"famsize\", \"GT3\", \"1\"))\n",
    "df = df.withColumn(\"Pstatus\", regexp_replace(\"Pstatus\", \"A\", \"0\"))\n",
    "df = df.withColumn(\"Pstatus\", regexp_replace(\"Pstatus\", \"T\", \"1\"))\n",
    "df = df.withColumn(\"Mjob\", regexp_replace(\"Mjob\", \"other\", \"0\"))\n",
    "df = df.withColumn(\"Mjob\", regexp_replace(\"Mjob\", \"at_home\", \"1\"))\n",
    "df = df.withColumn(\"Mjob\", regexp_replace(\"Mjob\", \"teacher\", \"2\"))\n",
    "df = df.withColumn(\"Mjob\", regexp_replace(\"Mjob\", \"services\", \"3\"))\n",
    "df = df.withColumn(\"Mjob\", regexp_replace(\"Mjob\", \"health\", \"4\"))\n",
    "df = df.withColumn(\"Fjob\", regexp_replace(\"Fjob\", \"other\", \"0\"))\n",
    "df = df.withColumn(\"Fjob\", regexp_replace(\"Fjob\", \"at_home\", \"1\"))\n",
    "df = df.withColumn(\"Fjob\", regexp_replace(\"Fjob\", \"teacher\", \"2\"))\n",
    "df = df.withColumn(\"Fjob\", regexp_replace(\"Fjob\", \"services\", \"3\"))\n",
    "df = df.withColumn(\"Fjob\", regexp_replace(\"Fjob\", \"health\", \"4\"))\n",
    "df = df.withColumn(\"reason\", regexp_replace(\"reason\", \"other\", \"0\"))\n",
    "df = df.withColumn(\"reason\", regexp_replace(\"reason\", \"home\", \"1\"))\n",
    "df = df.withColumn(\"reason\", regexp_replace(\"reason\", \"reputation\", \"2\"))\n",
    "df = df.withColumn(\"reason\", regexp_replace(\"reason\", \"course\", \"3\"))\n",
    "df = df.withColumn(\"guardian\", regexp_replace(\"guardian\", \"father\", \"1\"))\n",
    "df = df.withColumn(\"guardian\", regexp_replace(\"guardian\", \"mother\", \"2\"))\n",
    "df = df.withColumn(\"guardian\", regexp_replace(\"guardian\", \"other\", \"0\"))\n",
    "df = df.withColumn(\"schoolsup\", regexp_replace(\"schoolsup\", \"no\", \"0\"))\n",
    "df = df.withColumn(\"schoolsup\", regexp_replace(\"schoolsup\", \"yes\", \"1\"))\n",
    "df = df.withColumn(\"famsup\", regexp_replace(\"famsup\", \"no\", \"0\"))\n",
    "df = df.withColumn(\"famsup\", regexp_replace(\"famsup\", \"yes\", \"1\"))\n",
    "df = df.withColumn(\"paid\", regexp_replace(\"paid\", \"no\", \"0\"))\n",
    "df = df.withColumn(\"paid\", regexp_replace(\"paid\", \"yes\", \"1\"))\n",
    "df = df.withColumn(\"activities\", regexp_replace(\"activities\", \"no\", \"0\"))\n",
    "df = df.withColumn(\"activities\", regexp_replace(\"activities\", \"yes\", \"1\"))\n",
    "df = df.withColumn(\"nursery\", regexp_replace(\"nursery\", \"no\", \"0\"))\n",
    "df = df.withColumn(\"nursery\", regexp_replace(\"nursery\", \"yes\", \"1\"))\n",
    "df = df.withColumn(\"higher\", regexp_replace(\"higher\", \"no\", \"0\"))\n",
    "df = df.withColumn(\"higher\", regexp_replace(\"higher\", \"yes\", \"1\"))\n",
    "df = df.withColumn(\"internet\", regexp_replace(\"internet\", \"no\", \"0\"))\n",
    "df = df.withColumn(\"internet\", regexp_replace(\"internet\", \"yes\", \"1\"))\n",
    "df = df.withColumn(\"romantic\", regexp_replace(\"romantic\", \"no\", \"0\"))\n",
    "df = df.withColumn(\"romantic\", regexp_replace(\"romantic\", \"yes\", \"1\"))\n",
    "#df.show()\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------#\n",
    "#Casteo de todos los datos de string a int\n",
    "df = df.withColumn('school', df.school.astype(\"int\"))\n",
    "df = df.withColumn('sex', df.sex.astype(\"int\"))\n",
    "df = df.withColumn('age', df.age.astype(\"int\"))\n",
    "df = df.withColumn('address', df.address.astype(\"int\"))\n",
    "df = df.withColumn('famsize', df.famsize.astype(\"int\"))\n",
    "df = df.withColumn('Pstatus', df.Pstatus.astype(\"int\"))\n",
    "df = df.withColumn('Medu', df.Medu.astype(\"int\"))\n",
    "df = df.withColumn('Fedu', df.Fedu.astype(\"int\"))\n",
    "df = df.withColumn('Mjob', df.Mjob.astype(\"int\"))\n",
    "df = df.withColumn('Fjob', df.Fjob.astype(\"int\"))\n",
    "df = df.withColumn('reason', df.reason.astype(\"int\"))\n",
    "df = df.withColumn('guardian', df.guardian.astype(\"int\"))\n",
    "df = df.withColumn('traveltime', df.traveltime.astype(\"int\"))\n",
    "df = df.withColumn('studytime', df.studytime.astype(\"int\"))\n",
    "df = df.withColumn('failures', df.failures.astype(\"int\"))\n",
    "df = df.withColumn('schoolsup', df.schoolsup.astype(\"int\"))\n",
    "df = df.withColumn('famsup', df.famsup.astype(\"int\"))\n",
    "df = df.withColumn('paid', df.paid.astype(\"int\"))\n",
    "df = df.withColumn('activities', df.activities.astype(\"int\"))\n",
    "df = df.withColumn('nursery', df.nursery.astype(\"int\"))\n",
    "df = df.withColumn('higher', df.higher.astype(\"int\"))\n",
    "df = df.withColumn('internet', df.internet.astype(\"int\"))\n",
    "df = df.withColumn('romantic', df.romantic.astype(\"int\"))\n",
    "df = df.withColumn('famrel', df.famrel.astype(\"int\"))\n",
    "df = df.withColumn('freetime', df.freetime.astype(\"int\"))\n",
    "df = df.withColumn('goout', df.goout.astype(\"int\"))\n",
    "df = df.withColumn('Dalc', df.Dalc.astype(\"int\"))\n",
    "df = df.withColumn('Walc', df.Walc.astype(\"int\"))\n",
    "df = df.withColumn('health', df.health.astype(\"int\"))\n",
    "df = df.withColumn('absences', df.absences.astype(\"int\"))\n",
    "df = df.withColumn('G1', df.G1.astype(\"int\"))\n",
    "df = df.withColumn('G2', df.G2.astype(\"int\"))\n",
    "df = df.withColumn('G3', df.G3.astype(\"int\"))\n",
    "#df.show()\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------#\n",
    "\"\"\"\n",
    "Aquí defininimos un umbral del 60% de la nota máxima para\n",
    "establecer quienes aprueban y quienes reprueban.\n",
    "\n",
    "Nota: Es importante hacer un casteo luego de unir la partición de los datasets,\n",
    "obtuvimos algunos errores por omitir esto.\n",
    "\"\"\"\n",
    "\n",
    "#Estableciendo umbral para el primer periodo\n",
    "df = df.withColumn('G1', df.G1.astype(\"int\"))\n",
    "approved = df.filter(df.G1 >= 12)\n",
    "reproved = df.filter(df.G1 < 12)\n",
    "for i in range(12):\n",
    "    reproved = reproved.withColumn(\"G1\", regexp_replace(\"G1\", \"{}\".format(i), \"0\"))\n",
    "for i in range(12,20):\n",
    "    approved = approved.withColumn(\"G1\", regexp_replace(\"G1\", \"{}\".format(i), \"1\"))\n",
    "\n",
    "df = approved.union(reproved)\n",
    "df = df.withColumn('G1', df.G1.astype(\"int\"))\n",
    "\n",
    "#Estableciendo umbral para el segundo periodo\n",
    "df = df.withColumn('G2', df.G2.astype(\"int\"))\n",
    "approved = df.filter(df.G2 >= 12)\n",
    "reproved = df.filter(df.G2 < 12)\n",
    "for i in range(12):\n",
    "    reproved = reproved.withColumn(\"G2\", regexp_replace(\"G2\", \"{}\".format(i), \"0\"))\n",
    "for i in range(12,20):\n",
    "    approved = approved.withColumn(\"G2\", regexp_replace(\"G2\", \"{}\".format(i), \"1\"))\n",
    "df = approved.union(reproved)\n",
    "df = df.withColumn('G2', df.G2.astype(\"int\"))\n",
    "\n",
    "#Estableciendo umbral para el tercer periodo\n",
    "df = df.withColumn('G3', df.G3.astype(\"int\"))\n",
    "approved = df.filter(df.G3 >= 12)\n",
    "reproved = df.filter(df.G3 < 12)\n",
    "for i in range(12):\n",
    "    reproved = reproved.withColumn(\"G3\", regexp_replace(\"G3\", \"{}\".format(i), \"0\"))\n",
    "for i in range(12,20):\n",
    "    approved = approved.withColumn(\"G3\", regexp_replace(\"G3\", \"{}\".format(i), \"1\"))\n",
    "    \n",
    "#print('Número de estudiantes que rerobaron:', reproved.count())\n",
    "#print('Número de estudiantes que aprobaron:', approved.count())\n",
    "#Aquí obtuvimos 301 estudiantes reprobados y 348 estudiantes aprobados\n",
    "\n",
    "df = approved.union(reproved)\n",
    "df = df.withColumn('G3', df.G3.astype(\"int\"))\n",
    "\n",
    "#df.count()\n",
    "#df.show()\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------#\n",
    "#Ver medidas de centralidad\n",
    "#df.describe().toPandas()\n",
    "#df.toPandas().mode()\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nfor x in headings:\\n    print(x)\\n    plt.boxplot(df.toPandas()[x],vert = 0)\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------#\n",
    "#Visualizar datos atipicos\n",
    "\"\"\"\"\n",
    "for x in headings:\n",
    "    print(x)\n",
    "    plt.boxplot(df.toPandas()[x],vert = 0)\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\natypic_age_22=df.filter(df[\\'age\\'] == 22).count()\\natypic_p_status_0=df.filter(df[\\'Pstatus\\'] == 0).count()#viven padres juntos o separados \\natypic_travel_time_4=df.filter(df[\\'traveltime\\'] == 4).count()#tiempo de la casa a el colegio\\natypic_studytime_4=df.filter(df[\\'studytime\\'] == 4).count()#tiempo de estudio\\natypic_failures_1=df.filter(df[\\'failures\\'] == 1).count()#número de fallos de clases anteriores\\natypic_failures_2=df.filter(df[\\'failures\\'] == 2).count()\\natypic_failures_3=df.filter(df[\\'failures\\'] == 3).count() \\natypic_schoolsup_1=df.filter(df[\\'schoolsup\\'] == 1).count()#apoyo educativo adicional\\natypic_paid_1=df.filter(df[\\'paid\\'] == 1).count()#clases extra pagadas dentro de la asignatura del curso (portugués)\\natypic_nursery_0=df.filter(df[\\'nursery\\'] == 0).count()#asistio a la guarderia\\natypic_higher_0=df.filter(df[\\'higher\\'] == 0).count()#piensa  cursar estudios superiores\\natypic_internet_0=df.filter(df[\\'internet\\'] == 0).count()\\natypic_famrel_1=df.filter(df[\\'famrel\\'] == 1).count()#calidad de las relaciones familiares\\natypic_famrel_2=df.filter(df[\\'famrel\\'] == 2).count()\\natypic_freetime_1=df.filter(df[\\'freetime\\'] == 1).count()#tiempo libre despues de la escuela\\natypic_Dalc_4=df.filter(df[\\'Dalc\\'] == 4).count()# consumo de alcohol entre semana\\natypic_Dalc_5=df.filter(df[\\'Dalc\\'] == 5).count()\\natypic_absences=df.filter(df[\\'absences\\'] > 16).count()#numero de ausencias escolares\\n\\nprint(\"atypic_age_22:\",atypic_age_22)\\nprint(\"atypic_p_status_0:\",atypic_p_status_0)\\nprint(\"atypic_travel_time_4:\",atypic_travel_time_4)\\nprint(\"atypic_studytime_4:\",atypic_studytime_4)\\nprint(\"atypic_failures_1:\",atypic_failures_1)\\nprint(\"atypic_failures_2:\",atypic_failures_2)\\nprint(\"atypic_failures_3:\",atypic_failures_3)\\nprint(\"atypic_schoolsup_1:\",atypic_schoolsup_1)\\nprint(\"atypic_paid_1:\",atypic_paid_1)\\nprint(\"atypic_nursery_0:\",atypic_nursery_0)\\nprint(\"atypic_higher_0:\",atypic_higher_0)\\nprint(\"atypic_internet_0:\",atypic_internet_0)\\nprint(\"atypic_famrel_1:\",atypic_famrel_1)\\nprint(\"atypic_famrel_2:\",atypic_famrel_2)\\nprint(\"atypic_freetime_1:\",atypic_freetime_1)\\nprint(\"atypic_Dalc_4:\",atypic_Dalc_4)\\nprint(\"atypic_Dalc_5:\",atypic_Dalc_5)\\nprint(\"atypic_absences:\",atypic_absences)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------#\n",
    "#cantidad de datos atipicos\n",
    "\"\"\"\n",
    "atypic_age_22=df.filter(df['age'] == 22).count()\n",
    "atypic_p_status_0=df.filter(df['Pstatus'] == 0).count()#viven padres juntos o separados \n",
    "atypic_travel_time_4=df.filter(df['traveltime'] == 4).count()#tiempo de la casa a el colegio\n",
    "atypic_studytime_4=df.filter(df['studytime'] == 4).count()#tiempo de estudio\n",
    "atypic_failures_1=df.filter(df['failures'] == 1).count()#número de fallos de clases anteriores\n",
    "atypic_failures_2=df.filter(df['failures'] == 2).count()\n",
    "atypic_failures_3=df.filter(df['failures'] == 3).count() \n",
    "atypic_schoolsup_1=df.filter(df['schoolsup'] == 1).count()#apoyo educativo adicional\n",
    "atypic_paid_1=df.filter(df['paid'] == 1).count()#clases extra pagadas dentro de la asignatura del curso (portugués)\n",
    "atypic_nursery_0=df.filter(df['nursery'] == 0).count()#asistio a la guarderia\n",
    "atypic_higher_0=df.filter(df['higher'] == 0).count()#piensa  cursar estudios superiores\n",
    "atypic_internet_0=df.filter(df['internet'] == 0).count()\n",
    "atypic_famrel_1=df.filter(df['famrel'] == 1).count()#calidad de las relaciones familiares\n",
    "atypic_famrel_2=df.filter(df['famrel'] == 2).count()\n",
    "atypic_freetime_1=df.filter(df['freetime'] == 1).count()#tiempo libre despues de la escuela\n",
    "atypic_Dalc_4=df.filter(df['Dalc'] == 4).count()# consumo de alcohol entre semana\n",
    "atypic_Dalc_5=df.filter(df['Dalc'] == 5).count()\n",
    "atypic_absences=df.filter(df['absences'] > 16).count()#numero de ausencias escolares\n",
    "\n",
    "print(\"atypic_age_22:\",atypic_age_22)\n",
    "print(\"atypic_p_status_0:\",atypic_p_status_0)\n",
    "print(\"atypic_travel_time_4:\",atypic_travel_time_4)\n",
    "print(\"atypic_studytime_4:\",atypic_studytime_4)\n",
    "print(\"atypic_failures_1:\",atypic_failures_1)\n",
    "print(\"atypic_failures_2:\",atypic_failures_2)\n",
    "print(\"atypic_failures_3:\",atypic_failures_3)\n",
    "print(\"atypic_schoolsup_1:\",atypic_schoolsup_1)\n",
    "print(\"atypic_paid_1:\",atypic_paid_1)\n",
    "print(\"atypic_nursery_0:\",atypic_nursery_0)\n",
    "print(\"atypic_higher_0:\",atypic_higher_0)\n",
    "print(\"atypic_internet_0:\",atypic_internet_0)\n",
    "print(\"atypic_famrel_1:\",atypic_famrel_1)\n",
    "print(\"atypic_famrel_2:\",atypic_famrel_2)\n",
    "print(\"atypic_freetime_1:\",atypic_freetime_1)\n",
    "print(\"atypic_Dalc_4:\",atypic_Dalc_4)\n",
    "print(\"atypic_Dalc_5:\",atypic_Dalc_5)\n",
    "print(\"atypic_absences:\",atypic_absences)\n",
    "\"\"\"\n",
    "\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------#\n",
    "\"\"\"\n",
    "Eliminación de datos atipicos\n",
    "Nota: Para esta fase establecimos que estabamos dispuestos a eliminar hasta un 10%\n",
    "del total de los datos del dataset (649).\n",
    "\"\"\"\n",
    "\n",
    "df=df.filter(df['age'] != 22)\n",
    "df=df.filter(df['traveltime'] != 4)\n",
    "df=df.filter(df['absences'] <17)\n",
    "df=df.filter(df['Dalc'] != 5)\n",
    "#df.count()\n",
    "#Al depurar los datos atípicos, terminamos con un total de 608 datos.\n",
    "\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\napproved = df.filter(df.G3 == 1)\\nreproved = df.filter(df.G3 == 0)\\nprint(\"cantidad final de estudiantes aprobados\",approved.count())\\nprint(\"cantidad final de estudiantes reprobados\",reproved.count())\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mirar balance de los datos\n",
    "\"\"\"\n",
    "approved = df.filter(df.G3 == 1)\n",
    "reproved = df.filter(df.G3 == 0)\n",
    "print(\"cantidad final de estudiantes aprobados\",approved.count())\n",
    "print(\"cantidad final de estudiantes reprobados\",reproved.count())\n",
    "\"\"\"\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicar un balanceo de los datos reduciendo la clase mayorataria\n",
    "approved=approved.sample(fraction=0.809,seed = 9403040)\n",
    "#print( \"approved\",approved.count())\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizar la correlación de las variables\n",
    "#correlacion = correlation(df,headings)\n",
    "#sns.heatmap(correlacion, square=True)\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Correlaciones positivamente fuertes\\nprint('Correlación entre G1 y G2:', df.corr('G1','G2'))\\nprint('Correlación entre G1 y G3:', df.corr('G1','G3'))\\nprint('Correlación entre G2 y G3:', df.corr('G2','G3'))\\n\\n#Correlaciones positivamente moderadas\\nprint('Correlación entre Medu y Fedu:', df.corr('Medu','Fedu'))\\nprint('Correlación entre Walc y Dalc:', df.corr('Walc','Dalc'))\\n\\n#Correlaciones negativamente moderadas\\nprint('Correlación entre school y address:', df.corr('school','address'))\\nprint('Correlación entre traveltime y address:', df.corr('traveltime','address'))\\nprint('Correlación entre failures y G1:', df.corr('failures','G1'))\\nprint('Correlación entre failures y G2:', df.corr('failures','G2'))\\nprint('Correlación entre failures y G3:', df.corr('failures','G3'))\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analizar correlaciones a partir del mapa de calor de correlaciones\n",
    "\"\"\"\n",
    "#Correlaciones positivamente fuertes\n",
    "print('Correlación entre G1 y G2:', df.corr('G1','G2'))\n",
    "print('Correlación entre G1 y G3:', df.corr('G1','G3'))\n",
    "print('Correlación entre G2 y G3:', df.corr('G2','G3'))\n",
    "\n",
    "#Correlaciones positivamente moderadas\n",
    "print('Correlación entre Medu y Fedu:', df.corr('Medu','Fedu'))\n",
    "print('Correlación entre Walc y Dalc:', df.corr('Walc','Dalc'))\n",
    "\n",
    "#Correlaciones negativamente moderadas\n",
    "print('Correlación entre school y address:', df.corr('school','address'))\n",
    "print('Correlación entre traveltime y address:', df.corr('traveltime','address'))\n",
    "print('Correlación entre failures y G1:', df.corr('failures','G1'))\n",
    "print('Correlación entre failures y G2:', df.corr('failures','G2'))\n",
    "print('Correlación entre failures y G3:', df.corr('failures','G3'))\n",
    "\"\"\"\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación de los datasets finales\n",
    "df2 = df.drop('G2')\n",
    "df1 = df2.drop('G1')\n",
    "\n",
    "vector1 = VectorAssembler(\n",
    "    inputCols=['school','sex','age','address','famsize','Pstatus','Medu','Fedu','Mjob',\n",
    " 'Fjob','reason','guardian','traveltime','studytime','failures','schoolsup',\n",
    " 'famsup','paid','activities','nursery','higher','internet','romantic',\n",
    " 'famrel','freetime','goout','Dalc','Walc','health','absences'], outputCol=\"features\")\n",
    "\n",
    "vector2 = VectorAssembler(\n",
    "    inputCols=['school','sex','age','address','famsize','Pstatus','Medu','Fedu','Mjob',\n",
    " 'Fjob','reason','guardian','traveltime','studytime','failures','schoolsup',\n",
    " 'famsup','paid','activities','nursery','higher','internet','romantic',\n",
    " 'famrel','freetime','goout','Dalc','Walc','health','absences','G1'], outputCol=\"features\")\n",
    "\n",
    "\n",
    "df1 = vector1.transform(df)\n",
    "df2 = vector2.transform(df)\n",
    "\n",
    "#df_temp.show(5)\n",
    "# get dataframe with all necessary data in the appropriate form\n",
    "df1 = df1.drop('school','sex','age','address','famsize','Pstatus','Medu','Fedu','Mjob',\n",
    " 'Fjob','reason','guardian','traveltime','studytime','failures','schoolsup',\n",
    " 'famsup','paid','activities','nursery','higher','internet','romantic',\n",
    " 'famrel','freetime','goout','Dalc','Walc','health','absences','G1','G2')\n",
    "\n",
    "df2 = df2.drop('school','sex','age','address','famsize','Pstatus','Medu','Fedu','Mjob',\n",
    " 'Fjob','reason','guardian','traveltime','studytime','failures','schoolsup',\n",
    " 'famsup','paid','activities','nursery','higher','internet','romantic',\n",
    " 'famrel','freetime','goout','Dalc','Walc','health','absences','G1','G2')\n",
    "\n",
    "#Partición de los dataframes\n",
    "train1,test1 = df1.randomSplit([0.7,0.3],seed=2102020)\n",
    "train2,test2 = df2.randomSplit([0.7,0.3],seed=2112020)\n",
    "\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8166666666666667\n",
      "Precision = 0.8412698412698413\n",
      "F1 score = 0.8134856820426011\n"
     ]
    }
   ],
   "source": [
    "#-------------------------REGRESION LOGISTICA-----------------------------#\n",
    "#NOTA: En este modelo se intento variar el parametro de maxIter en ambos datasets, pero este parametro no afectaba\n",
    "#el desempeño del modelo en este caso.\n",
    "#-------------------------------Dataset 1---------------------------------#\n",
    "\n",
    "#Modelo con el mejor desmepeño evaluado\n",
    "lr = LogisticRegression(labelCol=\"G3\", featuresCol=\"features\",maxIter=50, threshold=0.45, family='binomial')\n",
    "#Otros modelos evaluados\n",
    "#lr = LogisticRegression(labelCol=\"G3\", featuresCol=\"features\",maxIter=50,threshold=0.5, family='binomial')\n",
    "#lr = LogisticRegression(labelCol=\"G3\", featuresCol=\"features\",maxIter=50,threshold=0.55, family='binomial')\n",
    "#lr = LogisticRegression(labelCol=\"G3\", featuresCol=\"features\",maxIter=50,threshold=0.4, family='binomial')\n",
    "\n",
    "model = lr.fit(train1)\n",
    "\n",
    "#Realizar predicciones\n",
    "predictions = model.transform(test1)\n",
    "\n",
    "#Comparar manualmente las preddiciones\n",
    "#predictions.select(\"prediction\", \"G3\").show(5)\n",
    "\n",
    "#Métricas de evaluación\n",
    "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"G3\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = multi_evaluator.evaluate(predictions)\n",
    "\n",
    "multi_evaluator = multi_evaluator.setMetricName('precisionByLabel')\n",
    "precision = multi_evaluator.evaluate(predictions)\n",
    "\n",
    "multi_evaluator = multi_evaluator.setMetricName('f1')\n",
    "f1_score = multi_evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Accuracy = {}\".format(accuracy))\n",
    "print(\"Precision = {}\".format(precision))\n",
    "print(\"F1 score = {}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8351063829787234\n",
      "Precision = 0.7738095238095238\n",
      "F1 score = 0.8360067121313168\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------Dataset 2---------------------------------#\n",
    "\n",
    "#Modelo con el mejor desmepeño evaluado\n",
    "lr = LogisticRegression(labelCol=\"G3\", featuresCol=\"features\",maxIter=100, threshold=0.5, family='binomial')\n",
    "#Otros modelos evaluados\n",
    "#lr = LogisticRegression(labelCol=\"G3\", featuresCol=\"features\",maxIter=50,threshold=0.45, family='binomial')\n",
    "#lr = LogisticRegression(labelCol=\"G3\", featuresCol=\"features\",maxIter=100,threshold=0.55, family='binomial')\n",
    "#lr = LogisticRegression(labelCol=\"G3\", featuresCol=\"features\",maxIter=100,threshold=0.4, family='binomial')\n",
    "\n",
    "#Entrenar el modelo\n",
    "model = lr.fit(train2)\n",
    "\n",
    "#Realizar predicciones\n",
    "predictions = model.transform(test2)\n",
    "\n",
    "#Comparar manualmente las prediciones\n",
    "#predictions.select(\"prediction\", \"G3\").show(5)\n",
    "\n",
    "#Métricas de evaluación\n",
    "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"G3\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = multi_evaluator.evaluate(predictions)\n",
    "\n",
    "multi_evaluator = multi_evaluator.setMetricName('precisionByLabel')\n",
    "precision = multi_evaluator.evaluate(predictions)\n",
    "\n",
    "multi_evaluator = multi_evaluator.setMetricName('f1')\n",
    "f1_score = multi_evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Accuracy = {}\".format(accuracy))\n",
    "print(\"Precision = {}\".format(precision))\n",
    "print(\"F1 score = {}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'regParam: regularization parameter (>= 0). (default: 0.0)'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.explainParam('regParam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finaliza la sesión de spark\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
