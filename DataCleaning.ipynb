{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conocimiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando librerias\n",
    "import findspark \n",
    "findspark.init()\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql import SparkSession, DataFrameStatFunctions, DataFrameNaFunctions\n",
    "from pyspark.sql.functions import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------#\n",
    "#Calcula la correlación de todas las variables de un dataframe\n",
    "#Entradas  dataframe: Dataframe de Spark\n",
    "#          headings: encabezado del dataframe (nombre de cada columna)\n",
    "#Salidas   corr: Lista de listas con la correlación de todas las variables \n",
    "def correlation(dataframe,headings):\n",
    "    n = len(headings)\n",
    "    corr = [[1 for _ in range(n)] for _ in range(n)]\n",
    "    dic=dict()\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            corr[i][j] = dataframe.corr(headings[i],headings[j])\n",
    "            corr[j][i] = corr[i][j]\n",
    "            if corr[i][j]>0.70:\n",
    "                dic[(headings[i],headings[j])]=corr[i][j]\n",
    "    print(dic)          \n",
    "    return corr\n",
    "#----------------------------------------------------------------------------#\n",
    "\n",
    "#Encabezado del dataframe\n",
    "headings = ['school','sex','age','address','famsize','Pstatus','Medu','Fedu','Mjob',\n",
    " 'Fjob','reason','guardian','traveltime','studytime','failures','schoolsup',\n",
    " 'famsup','paid','activities','nursery','higher','internet','romantic',\n",
    " 'famrel','freetime','goout','Dalc','Walc','health','absences','G1','G2','G3']\n",
    "spark = SparkSession.builder.appName(\"Student\").getOrCreate()\n",
    "\n",
    "#Crear dataframe\n",
    "df=spark.read.csv('student-por.csv',sep=';',header=True)\n",
    "#df.show()\n",
    "\n",
    "#Tamaño del dataset\n",
    "#print(df.count())\n",
    "#El dataframe tiene 649 registros\n",
    "\n",
    "#Tipos de dato de cada variable\n",
    "#print(df.dtypes)\n",
    "#Todos los datos del dataframe inicial son de tipo string\n",
    "\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Null data\\ntotal_null = df.filter(\"school is null\").count() + df.filter(\"sex is null\").count() + df.filter(\"age is null\").count()\\ntotal_null+= df.filter(\"address is null\").count() + df.filter(\"famsize is null\").count() + df.filter(\"Pstatus is null\").count()\\ntotal_null+= df.filter(\"Medu is null\").count() + df.filter(\"Fedu is null\").count() + df.filter(\"Mjob is null\").count()\\ntotal_null+= df.filter(\"Fjob is null\").count() + df.filter(\"reason is null\").count() + df.filter(\"guardian is null\").count()\\ntotal_null+= df.filter(\"traveltime is null\").count() + df.filter(\"studytime is null\").count() + df.filter(\"failures is null\").count()\\ntotal_null+= df.filter(\"schoolsup is null\").count() + df.filter(\"famsup is null\").count() + df.filter(\"paid is null\").count()\\ntotal_null+= df.filter(\"activities is null\").count() + df.filter(\"nursery is null\").count() + df.filter(\"higher is null\").count()\\ntotal_null+= df.filter(\"internet is null\").count() + df.filter(\"romantic is null\").count() + df.filter(\"famrel is null\").count()\\ntotal_null+= df.filter(\"freetime is null\").count() + df.filter(\"goout is null\").count() + df.filter(\"Dalc is null\").count()\\ntotal_null+= df.filter(\"Walc is null\").count() + df.filter(\"health is null\").count() + df.filter(\"absences is null\").count()\\ntotal_null+= df.filter(\"G1 is null\").count() + df.filter(\"G2 is null\").count() + df.filter(\"G3 is null\").count()\\nprint(total_null)\\n#Encontramos que el dataframe inicial no tiene datos faltantes\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Null data\n",
    "total_null = df.filter(\"school is null\").count() + df.filter(\"sex is null\").count() + df.filter(\"age is null\").count()\n",
    "total_null+= df.filter(\"address is null\").count() + df.filter(\"famsize is null\").count() + df.filter(\"Pstatus is null\").count()\n",
    "total_null+= df.filter(\"Medu is null\").count() + df.filter(\"Fedu is null\").count() + df.filter(\"Mjob is null\").count()\n",
    "total_null+= df.filter(\"Fjob is null\").count() + df.filter(\"reason is null\").count() + df.filter(\"guardian is null\").count()\n",
    "total_null+= df.filter(\"traveltime is null\").count() + df.filter(\"studytime is null\").count() + df.filter(\"failures is null\").count()\n",
    "total_null+= df.filter(\"schoolsup is null\").count() + df.filter(\"famsup is null\").count() + df.filter(\"paid is null\").count()\n",
    "total_null+= df.filter(\"activities is null\").count() + df.filter(\"nursery is null\").count() + df.filter(\"higher is null\").count()\n",
    "total_null+= df.filter(\"internet is null\").count() + df.filter(\"romantic is null\").count() + df.filter(\"famrel is null\").count()\n",
    "total_null+= df.filter(\"freetime is null\").count() + df.filter(\"goout is null\").count() + df.filter(\"Dalc is null\").count()\n",
    "total_null+= df.filter(\"Walc is null\").count() + df.filter(\"health is null\").count() + df.filter(\"absences is null\").count()\n",
    "total_null+= df.filter(\"G1 is null\").count() + df.filter(\"G2 is null\").count() + df.filter(\"G3 is null\").count()\n",
    "print(total_null)\n",
    "#Encontramos que el dataframe inicial no tiene datos faltantes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Casteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------#\n",
    "#Reemplazar valores categoricos a númericos\n",
    "df = df.withColumn(\"school\", regexp_replace(\"school\", \"GP\", \"0\"))\n",
    "df = df.withColumn(\"school\", regexp_replace(\"school\", \"MS\", \"1\"))\n",
    "df = df.withColumn(\"sex\", regexp_replace(\"sex\", \"F\", \"0\"))\n",
    "df = df.withColumn(\"sex\", regexp_replace(\"sex\", \"M\", \"1\"))\n",
    "df = df.withColumn(\"address\", regexp_replace(\"address\", \"R\", \"0\"))\n",
    "df = df.withColumn(\"address\", regexp_replace(\"address\", \"U\", \"1\"))\n",
    "df = df.withColumn(\"famsize\", regexp_replace(\"famsize\", \"LE3\", \"0\"))\n",
    "df = df.withColumn(\"famsize\", regexp_replace(\"famsize\", \"GT3\", \"1\"))\n",
    "df = df.withColumn(\"Pstatus\", regexp_replace(\"Pstatus\", \"A\", \"0\"))\n",
    "df = df.withColumn(\"Pstatus\", regexp_replace(\"Pstatus\", \"T\", \"1\"))\n",
    "df = df.withColumn(\"Mjob\", regexp_replace(\"Mjob\", \"other\", \"0\"))\n",
    "df = df.withColumn(\"Mjob\", regexp_replace(\"Mjob\", \"at_home\", \"1\"))\n",
    "df = df.withColumn(\"Mjob\", regexp_replace(\"Mjob\", \"teacher\", \"2\"))\n",
    "df = df.withColumn(\"Mjob\", regexp_replace(\"Mjob\", \"services\", \"3\"))\n",
    "df = df.withColumn(\"Mjob\", regexp_replace(\"Mjob\", \"health\", \"4\"))\n",
    "df = df.withColumn(\"Fjob\", regexp_replace(\"Fjob\", \"other\", \"0\"))\n",
    "df = df.withColumn(\"Fjob\", regexp_replace(\"Fjob\", \"at_home\", \"1\"))\n",
    "df = df.withColumn(\"Fjob\", regexp_replace(\"Fjob\", \"teacher\", \"2\"))\n",
    "df = df.withColumn(\"Fjob\", regexp_replace(\"Fjob\", \"services\", \"3\"))\n",
    "df = df.withColumn(\"Fjob\", regexp_replace(\"Fjob\", \"health\", \"4\"))\n",
    "df = df.withColumn(\"reason\", regexp_replace(\"reason\", \"other\", \"0\"))\n",
    "df = df.withColumn(\"reason\", regexp_replace(\"reason\", \"home\", \"1\"))\n",
    "df = df.withColumn(\"reason\", regexp_replace(\"reason\", \"reputation\", \"2\"))\n",
    "df = df.withColumn(\"reason\", regexp_replace(\"reason\", \"course\", \"3\"))\n",
    "df = df.withColumn(\"guardian\", regexp_replace(\"guardian\", \"father\", \"1\"))\n",
    "df = df.withColumn(\"guardian\", regexp_replace(\"guardian\", \"mother\", \"2\"))\n",
    "df = df.withColumn(\"guardian\", regexp_replace(\"guardian\", \"other\", \"0\"))\n",
    "df = df.withColumn(\"schoolsup\", regexp_replace(\"schoolsup\", \"no\", \"0\"))\n",
    "df = df.withColumn(\"schoolsup\", regexp_replace(\"schoolsup\", \"yes\", \"1\"))\n",
    "df = df.withColumn(\"famsup\", regexp_replace(\"famsup\", \"no\", \"0\"))\n",
    "df = df.withColumn(\"famsup\", regexp_replace(\"famsup\", \"yes\", \"1\"))\n",
    "df = df.withColumn(\"paid\", regexp_replace(\"paid\", \"no\", \"0\"))\n",
    "df = df.withColumn(\"paid\", regexp_replace(\"paid\", \"yes\", \"1\"))\n",
    "df = df.withColumn(\"activities\", regexp_replace(\"activities\", \"no\", \"0\"))\n",
    "df = df.withColumn(\"activities\", regexp_replace(\"activities\", \"yes\", \"1\"))\n",
    "df = df.withColumn(\"nursery\", regexp_replace(\"nursery\", \"no\", \"0\"))\n",
    "df = df.withColumn(\"nursery\", regexp_replace(\"nursery\", \"yes\", \"1\"))\n",
    "df = df.withColumn(\"higher\", regexp_replace(\"higher\", \"no\", \"0\"))\n",
    "df = df.withColumn(\"higher\", regexp_replace(\"higher\", \"yes\", \"1\"))\n",
    "df = df.withColumn(\"internet\", regexp_replace(\"internet\", \"no\", \"0\"))\n",
    "df = df.withColumn(\"internet\", regexp_replace(\"internet\", \"yes\", \"1\"))\n",
    "df = df.withColumn(\"romantic\", regexp_replace(\"romantic\", \"no\", \"0\"))\n",
    "df = df.withColumn(\"romantic\", regexp_replace(\"romantic\", \"yes\", \"1\"))\n",
    "#df.show()\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------#\n",
    "#Casteo de todos los datos de string a int\n",
    "df = df.withColumn('school', df.school.astype(\"int\"))\n",
    "df = df.withColumn('sex', df.sex.astype(\"int\"))\n",
    "df = df.withColumn('age', df.age.astype(\"int\"))\n",
    "df = df.withColumn('address', df.address.astype(\"int\"))\n",
    "df = df.withColumn('famsize', df.famsize.astype(\"int\"))\n",
    "df = df.withColumn('Pstatus', df.Pstatus.astype(\"int\"))\n",
    "df = df.withColumn('Medu', df.Medu.astype(\"int\"))\n",
    "df = df.withColumn('Fedu', df.Fedu.astype(\"int\"))\n",
    "df = df.withColumn('Mjob', df.Mjob.astype(\"int\"))\n",
    "df = df.withColumn('Fjob', df.Fjob.astype(\"int\"))\n",
    "df = df.withColumn('reason', df.reason.astype(\"int\"))\n",
    "df = df.withColumn('guardian', df.guardian.astype(\"int\"))\n",
    "df = df.withColumn('traveltime', df.traveltime.astype(\"int\"))\n",
    "df = df.withColumn('studytime', df.studytime.astype(\"int\"))\n",
    "df = df.withColumn('failures', df.failures.astype(\"int\"))\n",
    "df = df.withColumn('schoolsup', df.schoolsup.astype(\"int\"))\n",
    "df = df.withColumn('famsup', df.famsup.astype(\"int\"))\n",
    "df = df.withColumn('paid', df.paid.astype(\"int\"))\n",
    "df = df.withColumn('activities', df.activities.astype(\"int\"))\n",
    "df = df.withColumn('nursery', df.nursery.astype(\"int\"))\n",
    "df = df.withColumn('higher', df.higher.astype(\"int\"))\n",
    "df = df.withColumn('internet', df.internet.astype(\"int\"))\n",
    "df = df.withColumn('romantic', df.romantic.astype(\"int\"))\n",
    "df = df.withColumn('famrel', df.famrel.astype(\"int\"))\n",
    "df = df.withColumn('freetime', df.freetime.astype(\"int\"))\n",
    "df = df.withColumn('goout', df.goout.astype(\"int\"))\n",
    "df = df.withColumn('Dalc', df.Dalc.astype(\"int\"))\n",
    "df = df.withColumn('Walc', df.Walc.astype(\"int\"))\n",
    "df = df.withColumn('health', df.health.astype(\"int\"))\n",
    "df = df.withColumn('absences', df.absences.astype(\"int\"))\n",
    "df = df.withColumn('G1', df.G1.astype(\"int\"))\n",
    "df = df.withColumn('G2', df.G2.astype(\"int\"))\n",
    "df = df.withColumn('G3', df.G3.astype(\"int\"))\n",
    "\n",
    "#df.show()\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------#\n",
    "\"\"\"\n",
    "Aquí defininimos un umbral del 60% de la nota máxima para\n",
    "establecer quienes aprueban y quienes reprueban.\n",
    "\n",
    "Nota: Es importante hacer un casteo luego de unir la partición de los datasets,\n",
    "obtuvimos algunos errores por omitir esto.\n",
    "\"\"\"\n",
    "\n",
    "#Estableciendo umbral para el primer periodo\n",
    "df = df.withColumn('G1', df.G1.astype(\"int\"))\n",
    "approved = df.filter(df.G1 >= 12)\n",
    "reproved = df.filter(df.G1 < 12)\n",
    "for i in range(12):\n",
    "    reproved = reproved.withColumn(\"G1\", regexp_replace(\"G1\", \"{}\".format(i), \"0\"))\n",
    "for i in range(12,20):\n",
    "    approved = approved.withColumn(\"G1\", regexp_replace(\"G1\", \"{}\".format(i), \"1\"))\n",
    "\n",
    "df = approved.union(reproved)\n",
    "df = df.withColumn('G1', df.G1.astype(\"int\"))\n",
    "\n",
    "#Estableciendo umbral para el segundo periodo\n",
    "df = df.withColumn('G2', df.G2.astype(\"int\"))\n",
    "approved = df.filter(df.G2 >= 12)\n",
    "reproved = df.filter(df.G2 < 12)\n",
    "for i in range(12):\n",
    "    reproved = reproved.withColumn(\"G2\", regexp_replace(\"G2\", \"{}\".format(i), \"0\"))\n",
    "for i in range(12,20):\n",
    "    approved = approved.withColumn(\"G2\", regexp_replace(\"G2\", \"{}\".format(i), \"1\"))\n",
    "df = approved.union(reproved)\n",
    "df = df.withColumn('G2', df.G2.astype(\"int\"))\n",
    "\n",
    "#Estableciendo umbral para el tercer periodo\n",
    "df = df.withColumn('G3', df.G3.astype(\"int\"))\n",
    "approved = df.filter(df.G3 >= 12)\n",
    "reproved = df.filter(df.G3 < 12)\n",
    "for i in range(12):\n",
    "    reproved = reproved.withColumn(\"G3\", regexp_replace(\"G3\", \"{}\".format(i), \"0\"))\n",
    "for i in range(12,20):\n",
    "    approved = approved.withColumn(\"G3\", regexp_replace(\"G3\", \"{}\".format(i), \"1\"))\n",
    "    \n",
    "#print('Número de estudiantes que rerobaron:', reproved.count())\n",
    "#print('Número de estudiantes que aprobaron:', approved.count())\n",
    "#Aquí obtuvimos 301 estudiantes reprobados y 348 estudiantes aprobados\n",
    "\n",
    "df = approved.union(reproved)\n",
    "df = df.withColumn('G3', df.G3.astype(\"int\"))\n",
    "\n",
    "#df.count()\n",
    "#df.show()\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------#\n",
    "#Ver medidas de centralidad\n",
    "#df.describe().toPandas()\n",
    "#df.toPandas().mode()\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nfor x in headings:\\n    print(x)\\n    plt.boxplot(df.toPandas()[x],vert = 0)\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------#\n",
    "#Visualizar datos atipicos\n",
    "\"\"\"\"\n",
    "for x in headings:\n",
    "    print(x)\n",
    "    plt.boxplot(df.toPandas()[x],vert = 0)\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\natypic_age_22=df.filter(df[\\'age\\'] == 22).count()\\natypic_p_status_0=df.filter(df[\\'Pstatus\\'] == 0).count()#viven padres juntos o separados \\natypic_travel_time_4=df.filter(df[\\'traveltime\\'] == 4).count()#tiempo de la casa a el colegio\\natypic_studytime_4=df.filter(df[\\'studytime\\'] == 4).count()#tiempo de estudio\\natypic_failures_1=df.filter(df[\\'failures\\'] == 1).count()#número de fallos de clases anteriores\\natypic_failures_2=df.filter(df[\\'failures\\'] == 2).count()\\natypic_failures_3=df.filter(df[\\'failures\\'] == 3).count() \\natypic_schoolsup_1=df.filter(df[\\'schoolsup\\'] == 1).count()#apoyo educativo adicional\\natypic_paid_1=df.filter(df[\\'paid\\'] == 1).count()#clases extra pagadas dentro de la asignatura del curso (portugués)\\natypic_nursery_0=df.filter(df[\\'nursery\\'] == 0).count()#asistio a la guarderia\\natypic_higher_0=df.filter(df[\\'higher\\'] == 0).count()#piensa  cursar estudios superiores\\natypic_internet_0=df.filter(df[\\'internet\\'] == 0).count()\\natypic_famrel_1=df.filter(df[\\'famrel\\'] == 1).count()#calidad de las relaciones familiares\\natypic_famrel_2=df.filter(df[\\'famrel\\'] == 2).count()\\natypic_freetime_1=df.filter(df[\\'freetime\\'] == 1).count()#tiempo libre despues de la escuela\\natypic_Dalc_4=df.filter(df[\\'Dalc\\'] == 4).count()# consumo de alcohol entre semana\\natypic_Dalc_5=df.filter(df[\\'Dalc\\'] == 5).count()\\natypic_absences=df.filter(df[\\'absences\\'] > 16).count()#numero de ausencias escolares\\n\\nprint(\"atypic_age_22:\",atypic_age_22)\\nprint(\"atypic_p_status_0:\",atypic_p_status_0)\\nprint(\"atypic_travel_time_4:\",atypic_travel_time_4)\\nprint(\"atypic_studytime_4:\",atypic_studytime_4)\\nprint(\"atypic_failures_1:\",atypic_failures_1)\\nprint(\"atypic_failures_2:\",atypic_failures_2)\\nprint(\"atypic_failures_3:\",atypic_failures_3)\\nprint(\"atypic_schoolsup_1:\",atypic_schoolsup_1)\\nprint(\"atypic_paid_1:\",atypic_paid_1)\\nprint(\"atypic_nursery_0:\",atypic_nursery_0)\\nprint(\"atypic_higher_0:\",atypic_higher_0)\\nprint(\"atypic_internet_0:\",atypic_internet_0)\\nprint(\"atypic_famrel_1:\",atypic_famrel_1)\\nprint(\"atypic_famrel_2:\",atypic_famrel_2)\\nprint(\"atypic_freetime_1:\",atypic_freetime_1)\\nprint(\"atypic_Dalc_4:\",atypic_Dalc_4)\\nprint(\"atypic_Dalc_5:\",atypic_Dalc_5)\\nprint(\"atypic_absences:\",atypic_absences)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------#\n",
    "#cantidad de datos atipicos\n",
    "\"\"\"\n",
    "atypic_age_22=df.filter(df['age'] == 22).count()\n",
    "atypic_p_status_0=df.filter(df['Pstatus'] == 0).count()#viven padres juntos o separados \n",
    "atypic_travel_time_4=df.filter(df['traveltime'] == 4).count()#tiempo de la casa a el colegio\n",
    "atypic_studytime_4=df.filter(df['studytime'] == 4).count()#tiempo de estudio\n",
    "atypic_failures_1=df.filter(df['failures'] == 1).count()#número de fallos de clases anteriores\n",
    "atypic_failures_2=df.filter(df['failures'] == 2).count()\n",
    "atypic_failures_3=df.filter(df['failures'] == 3).count() \n",
    "atypic_schoolsup_1=df.filter(df['schoolsup'] == 1).count()#apoyo educativo adicional\n",
    "atypic_paid_1=df.filter(df['paid'] == 1).count()#clases extra pagadas dentro de la asignatura del curso (portugués)\n",
    "atypic_nursery_0=df.filter(df['nursery'] == 0).count()#asistio a la guarderia\n",
    "atypic_higher_0=df.filter(df['higher'] == 0).count()#piensa  cursar estudios superiores\n",
    "atypic_internet_0=df.filter(df['internet'] == 0).count()\n",
    "atypic_famrel_1=df.filter(df['famrel'] == 1).count()#calidad de las relaciones familiares\n",
    "atypic_famrel_2=df.filter(df['famrel'] == 2).count()\n",
    "atypic_freetime_1=df.filter(df['freetime'] == 1).count()#tiempo libre despues de la escuela\n",
    "atypic_Dalc_4=df.filter(df['Dalc'] == 4).count()# consumo de alcohol entre semana\n",
    "atypic_Dalc_5=df.filter(df['Dalc'] == 5).count()\n",
    "atypic_absences=df.filter(df['absences'] > 16).count()#numero de ausencias escolares\n",
    "\n",
    "print(\"atypic_age_22:\",atypic_age_22)\n",
    "print(\"atypic_p_status_0:\",atypic_p_status_0)\n",
    "print(\"atypic_travel_time_4:\",atypic_travel_time_4)\n",
    "print(\"atypic_studytime_4:\",atypic_studytime_4)\n",
    "print(\"atypic_failures_1:\",atypic_failures_1)\n",
    "print(\"atypic_failures_2:\",atypic_failures_2)\n",
    "print(\"atypic_failures_3:\",atypic_failures_3)\n",
    "print(\"atypic_schoolsup_1:\",atypic_schoolsup_1)\n",
    "print(\"atypic_paid_1:\",atypic_paid_1)\n",
    "print(\"atypic_nursery_0:\",atypic_nursery_0)\n",
    "print(\"atypic_higher_0:\",atypic_higher_0)\n",
    "print(\"atypic_internet_0:\",atypic_internet_0)\n",
    "print(\"atypic_famrel_1:\",atypic_famrel_1)\n",
    "print(\"atypic_famrel_2:\",atypic_famrel_2)\n",
    "print(\"atypic_freetime_1:\",atypic_freetime_1)\n",
    "print(\"atypic_Dalc_4:\",atypic_Dalc_4)\n",
    "print(\"atypic_Dalc_5:\",atypic_Dalc_5)\n",
    "print(\"atypic_absences:\",atypic_absences)\n",
    "\"\"\"\n",
    "\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------#\n",
    "\"\"\"\n",
    "Eliminación de datos atipicos\n",
    "Nota: Para esta fase establecimos que estabamos dispuestos a eliminar hasta un 10%\n",
    "del total de los datos del dataset (649).\n",
    "\"\"\"\n",
    "\n",
    "df=df.filter(df['age'] != 22)\n",
    "df=df.filter(df['traveltime'] != 4)\n",
    "df=df.filter(df['absences'] <17)\n",
    "df=df.filter(df['Dalc'] != 5)\n",
    "#df.count()\n",
    "#Al depurar los datos atípicos, terminamos con un total de 608 datos.\n",
    "\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\napproved = df.filter(df.G3 == 1)\\nreproved = df.filter(df.G3 == 0)\\nprint(\"cantidad final de estudiantes aprobados\",approved.count())\\nprint(\"cantidad final de estudiantes reprobados\",reproved.count())\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mirar balance de los datos\n",
    "\"\"\"\n",
    "approved = df.filter(df.G3 == 1)\n",
    "reproved = df.filter(df.G3 == 0)\n",
    "print(\"cantidad final de estudiantes aprobados\",approved.count())\n",
    "print(\"cantidad final de estudiantes reprobados\",reproved.count())\n",
    "\"\"\"\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicar un balanceo de los datos reduciendo la clase mayorataria\n",
    "approved=approved.sample(fraction=0.809,seed = 9403040)\n",
    "#print( \"approved\",approved.count())\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizar la correlación de las variables\n",
    "#correlacion = correlation(df,headings)\n",
    "#sns.heatmap(correlacion, square=True)\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Correlaciones positivamente fuertes\\nprint('Correlación entre G1 y G2:', df.corr('G1','G2'))\\nprint('Correlación entre G1 y G3:', df.corr('G1','G3'))\\nprint('Correlación entre G2 y G3:', df.corr('G2','G3'))\\n\\n#Correlaciones positivamente moderadas\\nprint('Correlación entre Medu y Fedu:', df.corr('Medu','Fedu'))\\nprint('Correlación entre Walc y Dalc:', df.corr('Walc','Dalc'))\\n\\n#Correlaciones negativamente moderadas\\nprint('Correlación entre school y address:', df.corr('school','address'))\\nprint('Correlación entre traveltime y address:', df.corr('traveltime','address'))\\nprint('Correlación entre failures y G1:', df.corr('failures','G1'))\\nprint('Correlación entre failures y G2:', df.corr('failures','G2'))\\nprint('Correlación entre failures y G3:', df.corr('failures','G3'))\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analizar correlaciones a partir del mapa de calor de correlaciones\n",
    "\"\"\"\n",
    "#Correlaciones positivamente fuertes\n",
    "print('Correlación entre G1 y G2:', df.corr('G1','G2'))\n",
    "print('Correlación entre G1 y G3:', df.corr('G1','G3'))\n",
    "print('Correlación entre G2 y G3:', df.corr('G2','G3'))\n",
    "\n",
    "#Correlaciones positivamente moderadas\n",
    "print('Correlación entre Medu y Fedu:', df.corr('Medu','Fedu'))\n",
    "print('Correlación entre Walc y Dalc:', df.corr('Walc','Dalc'))\n",
    "\n",
    "#Correlaciones negativamente moderadas\n",
    "print('Correlación entre school y address:', df.corr('school','address'))\n",
    "print('Correlación entre traveltime y address:', df.corr('traveltime','address'))\n",
    "print('Correlación entre failures y G1:', df.corr('failures','G1'))\n",
    "print('Correlación entre failures y G2:', df.corr('failures','G2'))\n",
    "print('Correlación entre failures y G3:', df.corr('failures','G3'))\n",
    "\"\"\"\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RL\n",
    "def logistic_Regression(df):\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"logistic_Regression\")\n",
    "\n",
    "    # divide our data into training and test sets (30% held out for testing)\n",
    "    (trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
    "    \n",
    "    lr = LogisticRegression(labelCol=\"G3\", featuresCol=\"features\",maxIter=10, regParam=0.3,\n",
    "                            elasticNetParam=0.8)\n",
    "\n",
    "    # Fit the model\n",
    "    model = lr.fit(trainingData)\n",
    "\n",
    "    # make predictions using our trained model\n",
    "    predictions = model.transform(testData)\n",
    "\n",
    "    # look at the result\n",
    "    predictions.select(\"prediction\", \"G3\").show(5)\n",
    "\n",
    "    # estimate the accuracy of the prediction\n",
    "    multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"G3\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = multi_evaluator.evaluate(predictions)\n",
    "\n",
    "    multi_evaluator = multi_evaluator.setMetricName('precisionByLabel')\n",
    "    precision = multi_evaluator.evaluate(predictions)\n",
    "    \n",
    "    multi_evaluator = multi_evaluator.setMetricName('recallByLabel')\n",
    "    recall = multi_evaluator.evaluate(predictions)\n",
    "\n",
    "    multi_evaluator = multi_evaluator.setMetricName('f1')\n",
    "    f1_score = multi_evaluator.evaluate(predictions)\n",
    "\n",
    "    print(\"Accuracy = {}\".format(accuracy))\n",
    "    print(\"Precision = {}\".format(precision))\n",
    "    print(\"Recall = {}\".format(recall))\n",
    "    print(\"F1 score = {}\".format(f1_score))\n",
    "\n",
    "    # print model summary\n",
    "    print(model)\n",
    "    # Print the coefficients and intercept for logistic regression\n",
    "    print(\"Coefficients: \" + str(model.coefficients))\n",
    "    print(\"Intercept: \" + str(model.intercept))\n",
    "    return (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "def random_Forest(df):\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"random_Forest\")\n",
    "    \n",
    "    # divide our data into training and test sets (30% held out for testing)\n",
    "    (trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
    "    \n",
    "    rf = RandomForestClassifier(labelCol=\"G3\", featuresCol=\"features\", numTrees=10)\n",
    "\n",
    "    # Fit the model\n",
    "    model = rf.fit(trainingData)\n",
    "\n",
    "    # make predictions using our trained model\n",
    "    predictions = model.transform(testData)\n",
    "\n",
    "    # look at the result\n",
    "    predictions.select(\"prediction\", \"G3\").show(5)\n",
    "\n",
    "    # estimate the accuracy of the prediction\n",
    "    multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"G3\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = multi_evaluator.evaluate(predictions)\n",
    "\n",
    "    multi_evaluator = multi_evaluator.setMetricName('precisionByLabel')\n",
    "    precision = multi_evaluator.evaluate(predictions)\n",
    "    \n",
    "    multi_evaluator = multi_evaluator.setMetricName('recallByLabel')\n",
    "    recall = multi_evaluator.evaluate(predictions)\n",
    "\n",
    "    multi_evaluator = multi_evaluator.setMetricName('f1')\n",
    "    f1_score = multi_evaluator.evaluate(predictions)\n",
    "\n",
    "    print(\"Accuracy = {}\".format(accuracy))\n",
    "    print(\"Precision = {}\".format(precision))\n",
    "    print(\"Recall = {}\".format(recall))\n",
    "    print(\"F1 score = {}\".format(f1_score))\n",
    "\n",
    "    # print model summary\n",
    "    print(model)\n",
    "    return (model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maquina de vectores de soporte "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maquina de vectores de soporte \n",
    "\n",
    "def mvs(df):\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"mvs\")\n",
    "    \n",
    "    # divide our data into training and test sets (30% held out for testing)\n",
    "    (trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
    "    \n",
    "    lsvc = LinearSVC(labelCol=\"G3\", featuresCol=\"features\", maxIter=10, regParam=0.1)\n",
    "\n",
    "    # Fit the model\n",
    "    model = lsvc.fit(trainingData)\n",
    "\n",
    "    # make predictions using our trained model\n",
    "    predictions = model.transform(testData)\n",
    "\n",
    "    # look at the result\n",
    "    predictions.select(\"prediction\", \"G3\").show(5)\n",
    "\n",
    "    # estimate the accuracy of the prediction\n",
    "    #Métricas de evaluación\n",
    "    multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"G3\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = multi_evaluator.evaluate(predictions)\n",
    "\n",
    "    multi_evaluator = multi_evaluator.setMetricName('precisionByLabel')\n",
    "    precision = multi_evaluator.evaluate(predictions)\n",
    "\n",
    "    multi_evaluator = multi_evaluator.setMetricName('f1')\n",
    "    f1_score = multi_evaluator.evaluate(predictions)\n",
    "    \n",
    "    multi_evaluator = multi_evaluator.setMetricName('recallByLabel')\n",
    "    recall = multi_evaluator.evaluate(predictions)\n",
    "    \n",
    "    print(\"Accuracy = {}\".format(accuracy))\n",
    "    print(\"Precision = {}\".format(precision))\n",
    "    print(\"Recall = {}\".format(recall))\n",
    "    print(\"F1 score = {}\".format(f1_score))\n",
    "   \n",
    "\n",
    "    # print model summary\n",
    "    print(model)\n",
    "    \n",
    "    # Print the coefficients and intercept for linear SVC\n",
    "    print(\"Coefficients: \" + str(model.coefficients))\n",
    "    print(\"Intercept: \" + str(model.intercept))\n",
    "    return (model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Técnicas de machine learning con los dos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin G1 y G2\n",
      "\n",
      "\n",
      "logistic_Regression\n",
      "+----------+---+\n",
      "|prediction| G3|\n",
      "+----------+---+\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "+----------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "Accuracy = 0.550561797752809\n",
      "Precision = 0.0\n",
      "Recall = 0.0\n",
      "F1 score = 0.39097866796938613\n",
      "LogisticRegressionModel: uid=LogisticRegression_e5949ed131b6, numClasses=2, numFeatures=30\n",
      "Coefficients: (30,[],[])\n",
      "Intercept: 0.2147753016436931\n",
      "\n",
      "\n",
      "Sin G1 y G2\n",
      "\n",
      "\n",
      "random_Forest\n",
      "+----------+---+\n",
      "|prediction| G3|\n",
      "+----------+---+\n",
      "|       0.0|  1|\n",
      "|       0.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "+----------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "Accuracy = 0.7640449438202247\n",
      "Precision = 0.7101449275362319\n",
      "Recall = 0.6901408450704225\n",
      "F1 score = 0.7634519350811485\n",
      "RandomForestClassificationModel: uid=RandomForestClassifier_8c4709731e2d, numTrees=10, numClasses=2, numFeatures=30\n",
      "\n",
      "\n",
      "Sin G1 y G2\n",
      "\n",
      "\n",
      "mvs\n",
      "+----------+---+\n",
      "|prediction| G3|\n",
      "+----------+---+\n",
      "|       0.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "+----------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "Accuracy = 0.7034883720930233\n",
      "Precision = 0.75\n",
      "Recall = 0.5316455696202531\n",
      "F1 score = 0.6945452072747055\n",
      "LinearSVCModel: uid=LinearSVC_616e414df804, numClasses=2, numFeatures=30\n",
      "Coefficients: [-0.7036222197814971,-0.3247200550319307,-0.024249517935537705,0.39037269412249004,0.010094449016957946,-0.08588298338618412,0.21409927393551065,0.026487641755760197,0.010734586715878793,0.001259420579399317,-0.02459229675618307,0.014817330954937903,-0.06905884172842147,0.2968316411529941,-0.8067790706637115,-0.028328369628438096,-0.01663526725215478,-0.017532461779913112,0.21723400534567303,0.019688443466147624,1.080432817541191,0.04549865496872298,-0.03480651452809427,0.01569503952313166,-0.20985691516535912,-0.04125219937573604,-0.05221802258006135,-0.03328659269368328,-0.025014245120727696,-0.03795630902909814]\n",
      "Intercept: 0.0035724112149802516\n",
      "\n",
      "\n",
      "#------------------------------------------------------------------------------------------#\n",
      "Sin G2\n",
      "\n",
      "\n",
      "logistic_Regression\n",
      "+----------+---+\n",
      "|prediction| G3|\n",
      "+----------+---+\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "+----------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "Accuracy = 0.8540540540540541\n",
      "Precision = 0.7878787878787878\n",
      "Recall = 0.9285714285714286\n",
      "F1 score = 0.8541819982514292\n",
      "LogisticRegressionModel: uid=LogisticRegression_429f87838e2e, numClasses=2, numFeatures=31\n",
      "Coefficients: (31,[2,30],[-0.008234971834083496,0.8449362958796311])\n",
      "Intercept: 0.03594757461045883\n",
      "\n",
      "\n",
      "Sin G2\n",
      "\n",
      "\n",
      "random_Forest\n",
      "+----------+---+\n",
      "|prediction| G3|\n",
      "+----------+---+\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "+----------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "Accuracy = 0.8524590163934426\n",
      "Precision = 0.8333333333333334\n",
      "Recall = 0.8620689655172413\n",
      "F1 score = 0.8525384035247886\n",
      "RandomForestClassificationModel: uid=RandomForestClassifier_84c0534a7c14, numTrees=10, numClasses=2, numFeatures=31\n",
      "\n",
      "\n",
      "Sin G2\n",
      "\n",
      "\n",
      "mvs\n",
      "+----------+---+\n",
      "|prediction| G3|\n",
      "+----------+---+\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "|       1.0|  1|\n",
      "+----------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "Accuracy = 0.8429319371727748\n",
      "Precision = 0.8170731707317073\n",
      "Recall = 0.8170731707317073\n",
      "F1 score = 0.8429319371727749\n",
      "LinearSVCModel: uid=LinearSVC_80462e4b737a, numClasses=2, numFeatures=31\n",
      "Coefficients: [-0.7257923997003792,-0.29056973129811847,-0.03491215060675464,0.18864384046164648,0.00669054832943389,-0.02905403172315392,0.09907572278599827,0.11048096524698207,0.03499227327202266,0.0028443217453918263,-0.028292178360516722,0.010317369666112543,-0.06814826940413221,0.13110479165990777,-0.7798571700199661,-0.20004199941863726,0.008695368519442716,-0.05997995384285723,0.15101962405235272,0.020898323237181306,0.5090094292173784,0.18116488707937964,-0.0019187936784571778,0.012580889929132293,-0.05409713054366102,-0.040554176794102156,-0.1512140090603523,-0.08307128184114161,-0.022005874176114854,-0.05083180127483293,1.522823089714792]\n",
      "Intercept: -0.057138267920187544\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    \n",
    "    #Creación de los datasets finales\n",
    "    vector1 = VectorAssembler(\n",
    "        inputCols=['school','sex','age','address','famsize','Pstatus','Medu','Fedu','Mjob',\n",
    "     'Fjob','reason','guardian','traveltime','studytime','failures','schoolsup',\n",
    "     'famsup','paid','activities','nursery','higher','internet','romantic',\n",
    "     'famrel','freetime','goout','Dalc','Walc','health','absences'], outputCol=\"features\")\n",
    "    df1_temp = vector1.transform(df)\n",
    "\n",
    "    #df_temp.show(5)\n",
    "    # get dataframe with all necessary data in the appropriate form\n",
    "    df1 = df1_temp.drop('school','sex','age','address','famsize','Pstatus','Medu','Fedu','Mjob',\n",
    "     'Fjob','reason','guardian','traveltime','studytime','failures','schoolsup',\n",
    "     'famsup','paid','activities','nursery','higher','internet','romantic',\n",
    "     'famrel','freetime','goout','Dalc','Walc','health','absences','G1','G2')\n",
    "\n",
    "    print(\"Sin G1 y G2\")\n",
    "    rl_model1=logistic_Regression(df1)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Sin G1 y G2\")\n",
    "    rf_model1=random_Forest(df1)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Sin G1 y G2\")\n",
    "    mvs_model1=mvs(df1)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"#------------------------------------------------------------------------------------------#\")\n",
    "    #----------------------------------------------------------------------------#\n",
    "\n",
    "    vector2 = VectorAssembler(\n",
    "        inputCols=['school','sex','age','address','famsize','Pstatus','Medu','Fedu','Mjob',\n",
    "     'Fjob','reason','guardian','traveltime','studytime','failures','schoolsup',\n",
    "     'famsup','paid','activities','nursery','higher','internet','romantic',\n",
    "     'famrel','freetime','goout','Dalc','Walc','health','absences','G1'], outputCol=\"features\")\n",
    "\n",
    "    df2_temp = vector2.transform(df)\n",
    "    #df2_temp.show(5)\n",
    "    # get dataframe with all necedf2_tempssary data in the appropriate form\n",
    "    df2 = df2_temp.drop('school','sex','age','address','famsize','Pstatus','Medu','Fedu','Mjob',\n",
    "     'Fjob','reason','guardian','traveltime','studytime','failures','schoolsup',\n",
    "     'famsup','paid','activities','nursery','higher','internet','romantic',\n",
    "     'famrel','freetime','goout','Dalc','Walc','health','absences','G1','G2')\n",
    "\n",
    "    print(\"Sin G2\")\n",
    "    rl_model2=logistic_Regression(df2)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Sin G2\")\n",
    "    rf_model2=random_Forest(df2)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "    print(\"Sin G2\")\n",
    "    mvs_model2=mvs(df2)\n",
    "    print(\"\\n\")\n",
    "\n",
    "main()\n",
    "#----------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finaliza la sesión de spark\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
