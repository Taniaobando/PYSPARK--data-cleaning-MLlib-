{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------#\n",
    "#       Procesamiento de grandes volumenes de datos 2020-2                   #\n",
    "#                     Proyecto 3 (Spark Graphx)                              #\n",
    "#                       Esteban Cardona Gil                                  #\n",
    "#                    Juan Camilo Gomez Muñoz                                 #\n",
    "#                     Tania C. Obando Suárez                                  #\n",
    "#----------------------------------------------------------------------------#\n",
    "\n",
    "#Importando librerias\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql import SparkSession, DataFrameStatFunctions, DataFrameNaFunctions\n",
    "from pyspark.sql.types import StructType,StructField, IntegerType\n",
    "from pyspark.sql.functions import *\n",
    "import random\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#------------------------FUNCIONES AUXILIARES----------------------------------#\n",
    "\n",
    "def correlation(dataframe,headings):\n",
    "    n = len(headings)\n",
    "    corr = [[1 for _ in range(n)] for _ in range(n)]\n",
    "    dic=dict()\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            corr[i][j] = dataframe.corr(headings[i],headings[j])\n",
    "            corr[j][i] = corr[i][j]\n",
    "            if corr[i][j]>0.70:\n",
    "                dic[(headings[i],headings[j])]=corr[i][j]\n",
    "    print(dic)\n",
    "    \n",
    "    #Analizar correlaciones a partir del mapa de calor de correlaciones\n",
    "\n",
    "    \"\"\"\n",
    "    #Correlaciones positivamente fuertes\n",
    "    print('Correlación entre G1 y G2:', df.corr('G1','G2'))\n",
    "    print('Correlación entre G1 y G3:', df.corr('G1','G3'))\n",
    "    print('Correlación entre G2 y G3:', df.corr('G2','G3'))\n",
    "\n",
    "    #Correlaciones positivamente moderadas\n",
    "    print('Correlación entre Medu y Fedu:', df.corr('Medu','Fedu'))\n",
    "    print('Correlación entre Walc y Dalc:', df.corr('Walc','Dalc'))\n",
    "\n",
    "    #Correlaciones negativamente moderadas\n",
    "    print('Correlación entre school y address:', df.corr('school','address'))\n",
    "    print('Correlación entre traveltime y address:', df.corr('traveltime','address'))\n",
    "    print('Correlación entre failures y G1:', df.corr('failures','G1'))\n",
    "    print('Correlación entre failures y G2:', df.corr('failures','G2'))\n",
    "    print('Correlación entre failures y G3:', df.corr('failures','G3'))\n",
    "    \"\"\"          \n",
    "    return corr\n",
    "\n",
    "#-----------------CONOCIMIENTO Y LIMPIEZA DE LOS DATOS------------------------#\n",
    "\n",
    "def  nullData(df):\n",
    "    #Datos nulos\n",
    "    total_null = df.filter(\"school is null\").count() + df.filter(\"sex is null\").count() + df.filter(\"age is null\").count()\n",
    "    total_null+= df.filter(\"address is null\").count() + df.filter(\"famsize is null\").count() + df.filter(\"Pstatus is null\").count()\n",
    "    total_null+= df.filter(\"Medu is null\").count() + df.filter(\"Fedu is null\").count() + df.filter(\"Mjob is null\").count()\n",
    "    total_null+= df.filter(\"Fjob is null\").count() + df.filter(\"reason is null\").count() + df.filter(\"guardian is null\").count()\n",
    "    total_null+= df.filter(\"traveltime is null\").count() + df.filter(\"studytime is null\").count() + df.filter(\"failures is null\").count()\n",
    "    total_null+= df.filter(\"schoolsup is null\").count() + df.filter(\"famsup is null\").count() + df.filter(\"paid is null\").count()\n",
    "    total_null+= df.filter(\"activities is null\").count() + df.filter(\"nursery is null\").count() + df.filter(\"higher is null\").count()\n",
    "    total_null+= df.filter(\"internet is null\").count() + df.filter(\"romantic is null\").count() + df.filter(\"famrel is null\").count()\n",
    "    total_null+= df.filter(\"freetime is null\").count() + df.filter(\"goout is null\").count() + df.filter(\"Dalc is null\").count()\n",
    "    total_null+= df.filter(\"Walc is null\").count() + df.filter(\"health is null\").count() + df.filter(\"absences is null\").count()\n",
    "    total_null+= df.filter(\"G1 is null\").count() + df.filter(\"G2 is null\").count() + df.filter(\"G3 is null\").count()\n",
    "    return(total_null)\n",
    "    #Encontramos que el dataframe inicial no tiene datos faltantes o datos nulos.\n",
    "\n",
    "def categoricalToNumerical(df):\n",
    "\n",
    "    #Reemplazar valores categoricos a númericos\n",
    "    df = df.withColumn(\"school\", regexp_replace(\"school\", \"GP\", \"0\"))\n",
    "    df = df.withColumn(\"school\", regexp_replace(\"school\", \"MS\", \"1\"))\n",
    "    df = df.withColumn(\"sex\", regexp_replace(\"sex\", \"F\", \"0\"))\n",
    "    df = df.withColumn(\"sex\", regexp_replace(\"sex\", \"M\", \"1\"))\n",
    "    df = df.withColumn(\"address\", regexp_replace(\"address\", \"R\", \"0\"))\n",
    "    df = df.withColumn(\"address\", regexp_replace(\"address\", \"U\", \"1\"))\n",
    "    df = df.withColumn(\"famsize\", regexp_replace(\"famsize\", \"LE3\", \"0\"))\n",
    "    df = df.withColumn(\"famsize\", regexp_replace(\"famsize\", \"GT3\", \"1\"))\n",
    "    df = df.withColumn(\"Pstatus\", regexp_replace(\"Pstatus\", \"A\", \"0\"))\n",
    "    df = df.withColumn(\"Pstatus\", regexp_replace(\"Pstatus\", \"T\", \"1\"))\n",
    "    df = df.withColumn(\"Mjob\", regexp_replace(\"Mjob\", \"other\", \"0\"))\n",
    "    df = df.withColumn(\"Mjob\", regexp_replace(\"Mjob\", \"at_home\", \"1\"))\n",
    "    df = df.withColumn(\"Mjob\", regexp_replace(\"Mjob\", \"teacher\", \"2\"))\n",
    "    df = df.withColumn(\"Mjob\", regexp_replace(\"Mjob\", \"services\", \"3\"))\n",
    "    df = df.withColumn(\"Mjob\", regexp_replace(\"Mjob\", \"health\", \"4\"))\n",
    "    df = df.withColumn(\"Fjob\", regexp_replace(\"Fjob\", \"other\", \"0\"))\n",
    "    df = df.withColumn(\"Fjob\", regexp_replace(\"Fjob\", \"at_home\", \"1\"))\n",
    "    df = df.withColumn(\"Fjob\", regexp_replace(\"Fjob\", \"teacher\", \"2\"))\n",
    "    df = df.withColumn(\"Fjob\", regexp_replace(\"Fjob\", \"services\", \"3\"))\n",
    "    df = df.withColumn(\"Fjob\", regexp_replace(\"Fjob\", \"health\", \"4\"))\n",
    "    df = df.withColumn(\"reason\", regexp_replace(\"reason\", \"other\", \"0\"))\n",
    "    df = df.withColumn(\"reason\", regexp_replace(\"reason\", \"home\", \"1\"))\n",
    "    df = df.withColumn(\"reason\", regexp_replace(\"reason\", \"reputation\", \"2\"))\n",
    "    df = df.withColumn(\"reason\", regexp_replace(\"reason\", \"course\", \"3\"))\n",
    "    df = df.withColumn(\"guardian\", regexp_replace(\"guardian\", \"father\", \"1\"))\n",
    "    df = df.withColumn(\"guardian\", regexp_replace(\"guardian\", \"mother\", \"2\"))\n",
    "    df = df.withColumn(\"guardian\", regexp_replace(\"guardian\", \"other\", \"0\"))\n",
    "    df = df.withColumn(\"schoolsup\", regexp_replace(\"schoolsup\", \"no\", \"0\"))\n",
    "    df = df.withColumn(\"schoolsup\", regexp_replace(\"schoolsup\", \"yes\", \"1\"))\n",
    "    df = df.withColumn(\"famsup\", regexp_replace(\"famsup\", \"no\", \"0\"))\n",
    "    df = df.withColumn(\"famsup\", regexp_replace(\"famsup\", \"yes\", \"1\"))\n",
    "    df = df.withColumn(\"paid\", regexp_replace(\"paid\", \"no\", \"0\"))\n",
    "    df = df.withColumn(\"paid\", regexp_replace(\"paid\", \"yes\", \"1\"))\n",
    "    df = df.withColumn(\"activities\", regexp_replace(\"activities\", \"no\", \"0\"))\n",
    "    df = df.withColumn(\"activities\", regexp_replace(\"activities\", \"yes\", \"1\"))\n",
    "    df = df.withColumn(\"nursery\", regexp_replace(\"nursery\", \"no\", \"0\"))\n",
    "    df = df.withColumn(\"nursery\", regexp_replace(\"nursery\", \"yes\", \"1\"))\n",
    "    df = df.withColumn(\"higher\", regexp_replace(\"higher\", \"no\", \"0\"))\n",
    "    df = df.withColumn(\"higher\", regexp_replace(\"higher\", \"yes\", \"1\"))\n",
    "    df = df.withColumn(\"internet\", regexp_replace(\"internet\", \"no\", \"0\"))\n",
    "    df = df.withColumn(\"internet\", regexp_replace(\"internet\", \"yes\", \"1\"))\n",
    "    df = df.withColumn(\"romantic\", regexp_replace(\"romantic\", \"no\", \"0\"))\n",
    "    df = df.withColumn(\"romantic\", regexp_replace(\"romantic\", \"yes\", \"1\"))\n",
    "    #df.show()\n",
    "    return(df)\n",
    "\n",
    "def stringToInt(df):\n",
    "\n",
    "    #Casteo de todos los datos de string a int\n",
    "    df = df.withColumn('school', df.school.astype(\"int\"))\n",
    "    df = df.withColumn('sex', df.sex.astype(\"int\"))\n",
    "    df = df.withColumn('age', df.age.astype(\"int\"))\n",
    "    df = df.withColumn('address', df.address.astype(\"int\"))\n",
    "    df = df.withColumn('famsize', df.famsize.astype(\"int\"))\n",
    "    df = df.withColumn('Pstatus', df.Pstatus.astype(\"int\"))\n",
    "    df = df.withColumn('Medu', df.Medu.astype(\"int\"))\n",
    "    df = df.withColumn('Fedu', df.Fedu.astype(\"int\"))\n",
    "    df = df.withColumn('Mjob', df.Mjob.astype(\"int\"))\n",
    "    df = df.withColumn('Fjob', df.Fjob.astype(\"int\"))\n",
    "    df = df.withColumn('reason', df.reason.astype(\"int\"))\n",
    "    df = df.withColumn('guardian', df.guardian.astype(\"int\"))\n",
    "    df = df.withColumn('traveltime', df.traveltime.astype(\"int\"))\n",
    "    df = df.withColumn('studytime', df.studytime.astype(\"int\"))\n",
    "    df = df.withColumn('failures', df.failures.astype(\"int\"))\n",
    "    df = df.withColumn('schoolsup', df.schoolsup.astype(\"int\"))\n",
    "    df = df.withColumn('famsup', df.famsup.astype(\"int\"))\n",
    "    df = df.withColumn('paid', df.paid.astype(\"int\"))\n",
    "    df = df.withColumn('activities', df.activities.astype(\"int\"))\n",
    "    df = df.withColumn('nursery', df.nursery.astype(\"int\"))\n",
    "    df = df.withColumn('higher', df.higher.astype(\"int\"))\n",
    "    df = df.withColumn('internet', df.internet.astype(\"int\"))\n",
    "    df = df.withColumn('romantic', df.romantic.astype(\"int\"))\n",
    "    df = df.withColumn('famrel', df.famrel.astype(\"int\"))\n",
    "    df = df.withColumn('freetime', df.freetime.astype(\"int\"))\n",
    "    df = df.withColumn('goout', df.goout.astype(\"int\"))\n",
    "    df = df.withColumn('Dalc', df.Dalc.astype(\"int\"))\n",
    "    df = df.withColumn('Walc', df.Walc.astype(\"int\"))\n",
    "    df = df.withColumn('health', df.health.astype(\"int\"))\n",
    "    df = df.withColumn('absences', df.absences.astype(\"int\"))\n",
    "    df = df.withColumn('G1', df.G1.astype(\"int\"))\n",
    "    df = df.withColumn('G2', df.G2.astype(\"int\"))\n",
    "    df = df.withColumn('G3', df.G3.astype(\"int\"))\n",
    "    #df.show()\n",
    "    return(df)\n",
    "\n",
    "def approvedOrReproved(df):\n",
    "    \"\"\"\n",
    "    Aquí defininimos un umbral del 60% de la nota máxima para\n",
    "    establecer quienes aprueban y quienes reprueban.\n",
    "\n",
    "    Nota: Es importante hacer un casteo luego de unir la partición de los datasets,\n",
    "    obtuvimos algunos errores por omitir esto.\n",
    "    \"\"\"\n",
    "\n",
    "    #Estableciendo umbral para el primer periodo\n",
    "    df = df.withColumn('G1', df.G1.astype(\"int\"))\n",
    "    approved = df.filter(df.G1 >= 12)\n",
    "    reproved = df.filter(df.G1 < 12)\n",
    "    for i in range(12):\n",
    "        reproved = reproved.withColumn(\"G1\", regexp_replace(\"G1\", \"{}\".format(i), \"0\"))\n",
    "    for i in range(12,20):\n",
    "        approved = approved.withColumn(\"G1\", regexp_replace(\"G1\", \"{}\".format(i), \"1\"))\n",
    "\n",
    "    df = approved.union(reproved)\n",
    "    df = df.withColumn('G1', df.G1.astype(\"int\"))\n",
    "\n",
    "    #Estableciendo umbral para el segundo periodo\n",
    "    df = df.withColumn('G2', df.G2.astype(\"int\"))\n",
    "    approved = df.filter(df.G2 >= 12)\n",
    "    reproved = df.filter(df.G2 < 12)\n",
    "    for i in range(12):\n",
    "        reproved = reproved.withColumn(\"G2\", regexp_replace(\"G2\", \"{}\".format(i), \"0\"))\n",
    "    for i in range(12,20):\n",
    "        approved = approved.withColumn(\"G2\", regexp_replace(\"G2\", \"{}\".format(i), \"1\"))\n",
    "    df = approved.union(reproved)\n",
    "    df = df.withColumn('G2', df.G2.astype(\"int\"))\n",
    "\n",
    "    #Estableciendo umbral para el tercer periodo\n",
    "    df = df.withColumn('G3', df.G3.astype(\"int\"))\n",
    "    approved = df.filter(df.G3 >= 12)\n",
    "    reproved = df.filter(df.G3 < 12)\n",
    "    for i in range(12):\n",
    "        reproved = reproved.withColumn(\"G3\", regexp_replace(\"G3\", \"{}\".format(i), \"0\"))\n",
    "    for i in range(12,20):\n",
    "        approved = approved.withColumn(\"G3\", regexp_replace(\"G3\", \"{}\".format(i), \"1\"))\n",
    "        \n",
    "    #print('Número de estudiantes que rerobaron:', reproved.count())\n",
    "    #print('Número de estudiantes que aprobaron:', approved.count())\n",
    "    #Aquí obtuvimos 301 estudiantes reprobados y 348 estudiantes aprobados\n",
    "\n",
    "    df = approved.union(reproved)\n",
    "    df = df.withColumn('G3', df.G3.astype(\"int\"))\n",
    "\n",
    "    #df.count()\n",
    "    #df.show()\n",
    "    return(df)\n",
    "\n",
    "def approvedOrReprovedG1(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    approved = df.filter(df.G1 == 1)\n",
    "    reproved = df.filter(df.G1 == 0)\n",
    "    \n",
    "\n",
    "    df = approved.union(reproved)\n",
    "    return(df)\n",
    "\n",
    "\n",
    "#----------------------------------ANALISIS-----------------------------------#\n",
    "\n",
    "#Visualización de las medidas de centralidad\n",
    "\n",
    "def describeData(df):\n",
    "    #información estadistica acerca de los datos \n",
    "    df.describe().toPandas()\n",
    "    df.toPandas().mode()\n",
    "\n",
    "def boxWhiskerPlot(df,headings):\n",
    "    #Diagramas de cajas y bigotes \n",
    "    for x in headings:\n",
    "        print(x)\n",
    "        plt.boxplot(df.toPandas()[x],vert = 0)\n",
    "        plt.show()\n",
    "\n",
    "def countAtypicValues(df):\n",
    "    #Analisis de los diagramas \n",
    "    #cantidad de datos atipicos\n",
    "\n",
    "    atypic_age_22=df.filter(df['age'] == 22).count()\n",
    "    atypic_p_status_0=df.filter(df['Pstatus'] == 0).count()#viven padres juntos o separados \n",
    "    atypic_travel_time_4=df.filter(df['traveltime'] == 4).count()#tiempo de la casa a el colegio\n",
    "    atypic_studytime_4=df.filter(df['studytime'] == 4).count()#tiempo de estudio\n",
    "    atypic_failures_1=df.filter(df['failures'] == 1).count()#número de fallos de clases anteriores\n",
    "    atypic_failures_2=df.filter(df['failures'] == 2).count()\n",
    "    atypic_failures_3=df.filter(df['failures'] == 3).count() \n",
    "    atypic_schoolsup_1=df.filter(df['schoolsup'] == 1).count()#apoyo educativo adicional\n",
    "    atypic_paid_1=df.filter(df['paid'] == 1).count()#clases extra pagadas dentro de la asignatura del curso (portugués)\n",
    "    atypic_nursery_0=df.filter(df['nursery'] == 0).count()#asistio a la guarderia\n",
    "    atypic_higher_0=df.filter(df['higher'] == 0).count()#piensa  cursar estudios superiores\n",
    "    atypic_internet_0=df.filter(df['internet'] == 0).count()\n",
    "    atypic_famrel_1=df.filter(df['famrel'] == 1).count()#calidad de las relaciones familiares\n",
    "    atypic_famrel_2=df.filter(df['famrel'] == 2).count()\n",
    "    atypic_freetime_1=df.filter(df['freetime'] == 1).count()#tiempo libre despues de la escuela\n",
    "    atypic_Dalc_4=df.filter(df['Dalc'] == 4).count()# consumo de alcohol entre semana\n",
    "    atypic_Dalc_5=df.filter(df['Dalc'] == 5).count()\n",
    "    atypic_absences=df.filter(df['absences'] > 16).count()#numero de ausencias escolares\n",
    "\n",
    "    print(\"atypic_age_22:\",atypic_age_22)\n",
    "    print(\"atypic_p_status_0:\",atypic_p_status_0)\n",
    "    print(\"atypic_travel_time_4:\",atypic_travel_time_4)\n",
    "    print(\"atypic_studytime_4:\",atypic_studytime_4)\n",
    "    print(\"atypic_failures_1:\",atypic_failures_1)\n",
    "    print(\"atypic_failures_2:\",atypic_failures_2)\n",
    "    print(\"atypic_failures_3:\",atypic_failures_3)\n",
    "    print(\"atypic_schoolsup_1:\",atypic_schoolsup_1)\n",
    "    print(\"atypic_paid_1:\",atypic_paid_1)\n",
    "    print(\"atypic_nursery_0:\",atypic_nursery_0)\n",
    "    print(\"atypic_higher_0:\",atypic_higher_0)\n",
    "    print(\"atypic_internet_0:\",atypic_internet_0)\n",
    "    print(\"atypic_famrel_1:\",atypic_famrel_1)\n",
    "    print(\"atypic_famrel_2:\",atypic_famrel_2)\n",
    "    print(\"atypic_freetime_1:\",atypic_freetime_1)\n",
    "    print(\"atypic_Dalc_4:\",atypic_Dalc_4)\n",
    "    print(\"atypic_Dalc_5:\",atypic_Dalc_5)\n",
    "    print(\"atypic_absences:\",atypic_absences)\n",
    "\n",
    "def dropAtypicValues(df):\n",
    "    \"\"\"\n",
    "    Eliminación de datos atipicos\n",
    "    Nota: Para esta fase establecimos que estabamos dispuestos a eliminar hasta un 10%\n",
    "    del total de los datos del dataset (649).\n",
    "    \"\"\"\n",
    "    df=df.filter(df['age'] != 22)\n",
    "    df=df.filter(df['traveltime'] != 4)\n",
    "    df=df.filter(df['absences'] <17)\n",
    "    df=df.filter(df['Dalc'] != 5)\n",
    "    #df.count()\n",
    "    #Al depurar los datos atípicos, terminamos con un total de 608 datos.\n",
    "    return(df)\n",
    "\n",
    "def dataBalancing(df):\n",
    "\n",
    "    #Mirar balance de los datos\n",
    "\n",
    "    approved = df.filter(df.G3 == 1)\n",
    "    reproved = df.filter(df.G3 == 0)\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"cantidad final de estudiantes aprobados\",approved.count())\n",
    "    print(\"cantidad final de estudiantes reprobados\",reproved.count())\n",
    "    \"\"\"\n",
    "\n",
    "    #Aplicar un balanceo de los datos reduciendo la clase mayorataria\n",
    "    approved=approved.sample(fraction=0.809,seed = 9403040)\n",
    "    #print( \"approved\",approved.count())\n",
    "    df = approved.union(reproved)\n",
    "\n",
    "    return(df)\n",
    "\n",
    "def preprocesar(df):\n",
    "    #Preprocesa los datos del dataframe\n",
    "    #Cantidad de datos nulos \n",
    "    nullData(df)\n",
    "    #Reemplazar valores categoricos a numericos\n",
    "    df=categoricalToNumerical(df)\n",
    "\n",
    "    #Convertir los datos de string a int\n",
    "    df=stringToInt(df)\n",
    "\n",
    "    #Convertir variables categorica a numericas\n",
    "    df=approvedOrReproved(df)\n",
    "\n",
    "    df = dataBalancing(df)\n",
    "    return df\n",
    "\n",
    "def atributos_grafo(df,drop_list):\n",
    "    #Elimina los atributos que no son de interes para la representación\n",
    "    #del grafo\n",
    "    while(len(drop_list)):\n",
    "        x = drop_list.pop()\n",
    "        df = df.drop(x)\n",
    "    return df\n",
    "\n",
    "@udf(returnType=IntegerType())\n",
    "def randomization(x):\n",
    "    if x is not None:\n",
    "        return x*random.randint(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------+------+--------+-----+----+----+------+--------+---+\n",
      "|age|traveltime|studytime|failures|famrel|freetime|goout|Dalc|Walc|health|absences| G1|\n",
      "+---+----------+---------+--------+------+--------+-----+----+----+------+--------+---+\n",
      "| 15|         1|        3|       0|     3|       2|    2|   1|   1|     5|       0|  1|\n",
      "| 16|         1|        2|       0|     5|       4|    2|   1|   2|     5|       6|  1|\n",
      "| 15|         1|        2|       0|     4|       2|    2|   1|   1|     1|       0|  1|\n",
      "| 15|         1|        2|       0|     5|       5|    1|   1|   1|     5|       0|  1|\n",
      "| 15|         1|        2|       0|     3|       3|    3|   1|   2|     2|       2|  1|\n",
      "| 15|         1|        1|       0|     4|       3|    3|   1|   3|     5|       0|  1|\n",
      "| 15|         2|        2|       0|     5|       4|    3|   1|   2|     3|       0|  1|\n",
      "| 16|         1|        1|       0|     4|       4|    4|   1|   2|     2|       6|  1|\n",
      "| 16|         1|        3|       0|     3|       2|    3|   1|   2|     2|      10|  1|\n",
      "| 16|         3|        2|       0|     5|       3|    2|   1|   1|     4|       2|  1|\n",
      "| 16|         1|        1|       0|     3|       1|    3|   1|   3|     5|       6|  1|\n",
      "| 16|         1|        2|       0|     5|       3|    3|   1|   1|     5|       2|  1|\n",
      "| 15|         1|        2|       0|     5|       3|    2|   1|   1|     2|       0|  1|\n",
      "| 16|         1|        1|       0|     5|       4|    3|   1|   1|     5|       4|  1|\n",
      "| 15|         1|        3|       0|     5|       4|    3|   1|   1|     4|       0|  1|\n",
      "| 16|         2|        3|       0|     2|       4|    3|   1|   1|     5|       4|  1|\n",
      "| 15|         1|        1|       0|     4|       3|    1|   1|   1|     2|       8|  1|\n",
      "| 16|         1|        4|       0|     4|       2|    2|   1|   1|     2|       2|  1|\n",
      "| 15|         1|        2|       0|     4|       4|    4|   1|   1|     3|       2|  1|\n",
      "| 16|         3|        2|       0|     4|       3|    3|   2|   3|     4|       0|  1|\n",
      "+---+----------+---------+--------+------+--------+-----+----+----+------+--------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lista de atributos no necesarios para la representación del grafo\n",
    "drop_list = ['school','sex','address','famsize','Pstatus','Medu','Fedu','Mjob',\n",
    "             'Fjob','reason','guardian','schoolsup','famsup','paid',\n",
    "             'activities','nursery','higher','internet','romantic','G2','G3']\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Student\").getOrCreate()\n",
    "\n",
    "#Crear dataframe\n",
    "df=spark.read.csv('student-por.csv',sep=';',header=True)\n",
    "\n",
    "#Realizar el preprocesamiento al dataframe\n",
    "df = preprocesar(df)\n",
    "\n",
    "#Eliminar atributos innecesarios\n",
    "df = atributos_grafo(df,drop_list)\n",
    "\n",
    "#Crear la columna de id\n",
    "df = df.withColumn(\"id\",monotonically_increasing_id())\n",
    "\n",
    "#Crear una columna constante para el factor social\n",
    "df = df.withColumn(\"social\",lit(1))\n",
    "\n",
    "#Reemplaza la constante de la columna social por un valor aleatorio en [1,5]\n",
    "df = df.withColumn(\"social\",randomization(df.social))\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
